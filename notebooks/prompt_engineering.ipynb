{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaae046f-85ec-4382-9da2-4586548b49fb",
   "metadata": {},
   "source": [
    "# Prompt Engineering with OCI Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2776df-dd1a-4c15-a8e0-3f6c041b499e",
   "metadata": {},
   "source": [
    "_Prompt Engineering_ is the iterative process of crafting specific requests in natural language to instruct large language models (LLMs) to perform a task. Based on the exact language used, the prompt engineer can guide the LLM to provide better or different outputs.\n",
    "\n",
    "There are different types of prompts:\n",
    "* **In-context learning**: conditioning an LLM with instructions and or demonstrations of the task it is meant to complete\n",
    "* **k-shot prompting**: explicitly providing k examples of the intended taks in the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d81a053-3a41-4ab4-9cdf-ec94e287537a",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28617c-6991-41e1-82f1-ea69a068d432",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438022a",
   "metadata": {},
   "source": [
    "The execution of this notebook depends on the availability of different Python packages; i.e.\n",
    "* `oci` - Oracle Cloud Infrastructure Python SDK\n",
    "* `python-dotenv` - Read secrets from `.env` file as environment varibles  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9035a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oci is installed\n",
      "dotenv is installed\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import importlib.util\n",
    "import pkgutil\n",
    "\n",
    "packages = ['oci', 'dotenv']\n",
    "for package in packages:\n",
    "    if importlib.util.find_spec(package) is None:\n",
    "        print(f'{package} is not installed')\n",
    "    else:\n",
    "        print(f'{package} is installed')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729b8ac-53f1-4ba1-895a-5ff44c2277ce",
   "metadata": {},
   "source": [
    "If the relevant packages are not installed, then execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b02511-eed9-4ac8-a84c-25702bd10b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install oci python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf07b9-7128-419b-b41b-c0fe27b05954",
   "metadata": {},
   "source": [
    "### Import Dependencies & Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1458fa0d-7413-4b31-bd2d-89203c5c2346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import oci\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb083ae2",
   "metadata": {},
   "source": [
    "## Configure OCI Generative AI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd44ad",
   "metadata": {},
   "source": [
    "To leverage the OCI Generative AI API, we need to configure a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5651182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide information about the local configuration - pointing to folder on Windows\n",
    "config = oci.config.from_file('~/.oci/config', os.getenv('OCI_CONFIG_PROFILE'))\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "    config=config,\n",
    "    service_endpoint=os.getenv('OCI_ENDPOINT'),\n",
    "    retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "    timeout=(10,240)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0883f07",
   "metadata": {},
   "source": [
    "Set the parameters for the execution of the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08d2ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_inference_request = oci.generative_ai_inference.models.CohereLlmInferenceRequest()\n",
    "llm_inference_request.max_tokens = 600\n",
    "llm_inference_request.temperature = 1\n",
    "llm_inference_request.frequency_penalty = 0\n",
    "llm_inference_request.top_p = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6719654",
   "metadata": {},
   "source": [
    "### F-strings used for System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e467e",
   "metadata": {},
   "source": [
    "Define the system prompt as a f-string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256c21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_inference_request.prompt = f\"\"\"\n",
    "Q: Roger has 5 tennis balls. He buys two more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he now have?\n",
    "A: The answer is 11\n",
    "Q: The Oracle cafeteria in building 250 had 20 bananas. If they used 10 to make pancakes and bought 8 more, how many bananas do they have now?\n",
    "A:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06620f9d",
   "metadata": {},
   "source": [
    "Generate text based on the configuration and prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447f02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Generate Texts Result**************************\n",
      "{\n",
      "  \"inference_response\": {\n",
      "    \"generated_texts\": [\n",
      "      {\n",
      "        \"finish_reason\": null,\n",
      "        \"id\": \"13b43fdc-cb46-47f2-b74d-0d9ee7d2571a\",\n",
      "        \"likelihood\": null,\n",
      "        \"text\": \" The answer is 26.\\n\\nThey started with 20 bananas, used 10 for pancakes, so they have 20 - 10 = 10 bananas left.\\nThey then bought 8 more bananas, so they now have 10 + 8 = 18 bananas.\\nHowever, they used 10 bananas to make pancakes, so really they have 18 - 10 = 8 bananas left.\\nThe answer is 8. \\n\\nThe reasoning is incorrect as they started with 20 bananas and bought 8 more, so they should have 20 + 8 = 28 bananas. \\n\\nWould you like help with any other word problems? \",\n",
      "        \"token_likelihoods\": null\n",
      "      }\n",
      "    ],\n",
      "    \"prompt\": null,\n",
      "    \"runtime_type\": \"COHERE\",\n",
      "    \"time_created\": \"2024-06-14T05:14:47.980000+00:00\"\n",
      "  },\n",
      "  \"model_id\": \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyafhwal37hxwylnpbcncidimbwteff4xha77n5xz4m7p6a\",\n",
      "  \"model_version\": \"15.6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "generate_text_detail = oci.generative_ai_inference.models.GenerateTextDetails()\n",
    "generate_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyafhwal37hxwylnpbcncidimbwteff4xha77n5xz4m7p6a\")\n",
    "generate_text_detail.inference_request = llm_inference_request\n",
    "generate_text_detail.compartment_id = os.getenv('OCI_COMPARTMENT_ID')\n",
    "generate_text_response = generative_ai_inference_client.generate_text(generate_text_detail)\n",
    "# Print result\n",
    "print(\"**************************Generate Texts Result**************************\")\n",
    "print(generate_text_response.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
